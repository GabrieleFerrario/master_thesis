{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34652bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.10.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.11.2)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (3.10.0.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchvision) (1.21.2)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchvision) (8.4.0)\n",
      "Collecting pyyaml==5.1\n",
      "  Using cached PyYAML-5.1-cp39-cp39-win_amd64.whl\n",
      "Installing collected packages: pyyaml\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 6.0\n",
      "    Uninstalling PyYAML-6.0:\n",
      "      Successfully uninstalled PyYAML-6.0\n",
      "Successfully installed pyyaml-5.1\n",
      "torch:  1.10 ; cuda:  cpu\n",
      "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cpu/torch1.10/index.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement detectron2 (from versions: none)\n",
      "ERROR: No matching distribution found for detectron2\n"
     ]
    }
   ],
   "source": [
    "! pip3 install torch torchvision torchaudio --upgrade\n",
    "\n",
    "!pip install pyyaml==5.1\n",
    "\n",
    "import torch\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "# Install detectron2 that matches the above pytorch version\n",
    "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
    "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/$CUDA_VERSION/torch$TORCH_VERSION/index.html\n",
    "# If there is not yet a detectron2 release that matches the given torch + CUDA version, you need to install a different pytorch.\n",
    "#torch:  1.10 ; cuda:  cu113\n",
    "#pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu113/torch1.10/index.html\n",
    "#pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/1.7.1/torch1.7/index.html\n",
    "\n",
    "# exit(0)  # After installation, you may need to \"restart runtime\" in Colab. This line can also restart runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da0ab5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch:  1.10 ; cuda:  cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b87acda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///C:/Users/gabriele.ferrario/OneDrive%20-%20Accenture/Desktop/tesi/datasets/flickr30k_images/detectron2\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: Pillow>=7.1 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from detectron2==0.6) (8.4.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from detectron2==0.6) (3.5.0)\n",
      "Requirement already satisfied: pycocotools>=2.0.2 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from detectron2==0.6) (2.0.3)\n",
      "Requirement already satisfied: termcolor>=1.1 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from detectron2==0.6) (1.1.0)\n",
      "Requirement already satisfied: yacs>=0.1.8 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from detectron2==0.6) (0.1.8)\n",
      "Requirement already satisfied: tabulate in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from detectron2==0.6) (0.8.9)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from detectron2==0.6) (2.0.0)\n",
      "Requirement already satisfied: tqdm>4.29.0 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from detectron2==0.6) (4.62.3)\n",
      "Requirement already satisfied: tensorboard in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from detectron2==0.6) (2.7.0)\n",
      "Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from detectron2==0.6) (0.1.5.post20211023)\n",
      "Requirement already satisfied: iopath<0.1.10,>=0.1.7 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from detectron2==0.6) (0.1.9)\n",
      "Requirement already satisfied: future in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from detectron2==0.6) (0.18.2)\n",
      "Requirement already satisfied: pydot in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from detectron2==0.6) (1.4.2)\n",
      "Requirement already satisfied: omegaconf>=2.1 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from detectron2==0.6) (2.1.1)\n",
      "Requirement already satisfied: hydra-core>=1.1 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from detectron2==0.6) (1.1.1)\n",
      "Requirement already satisfied: black==21.4b2 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from detectron2==0.6) (21.4b2)\n",
      "Requirement already satisfied: scipy>1.5.1 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from detectron2==0.6) (1.7.1)\n",
      "Requirement already satisfied: pathspec<1,>=0.8.1 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from black==21.4b2->detectron2==0.6) (0.9.0)\n",
      "Requirement already satisfied: click>=7.1.2 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from black==21.4b2->detectron2==0.6) (8.0.1)\n",
      "Requirement already satisfied: regex>=2020.1.8 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from black==21.4b2->detectron2==0.6) (2021.11.10)\n",
      "Requirement already satisfied: appdirs in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from black==21.4b2->detectron2==0.6) (1.4.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from black==21.4b2->detectron2==0.6) (0.4.3)\n",
      "Requirement already satisfied: toml>=0.10.1 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from black==21.4b2->detectron2==0.6) (0.10.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.21.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (5.1)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.8 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from hydra-core>=1.1->detectron2==0.6) (4.8)\n",
      "Requirement already satisfied: portalocker in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from iopath<0.1.10,>=0.1.7->detectron2==0.6) (2.3.2)\n",
      "Requirement already satisfied: setuptools>=18.0 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pycocotools>=2.0.2->detectron2==0.6) (49.2.1)\n",
      "Requirement already satisfied: cython>=0.27.3 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pycocotools>=2.0.2->detectron2==0.6) (0.29.24)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->detectron2==0.6) (4.28.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->detectron2==0.6) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->detectron2==0.6) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->detectron2==0.6) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->detectron2==0.6) (2.8.1)\n",
      "Requirement already satisfied: setuptools-scm>=4 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->detectron2==0.6) (6.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->detectron2==0.6) (21.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm>4.29.0->detectron2==0.6) (0.4.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard->detectron2==0.6) (3.3.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard->detectron2==0.6) (2.25.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard->detectron2==0.6) (1.8.1)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard->detectron2==0.6) (3.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard->detectron2==0.6) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard->detectron2==0.6) (2.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'C:\\Users\\gabriele.ferrario\\AppData\\Local\\Programs\\Python\\Python39\\python.exe' -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\gabriele.ferrario\\\\OneDrive - Accenture\\\\Desktop\\\\tesi\\\\datasets\\\\flickr30k_images\\\\detectron2\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\gabriele.ferrario\\\\OneDrive - Accenture\\\\Desktop\\\\tesi\\\\datasets\\\\flickr30k_images\\\\detectron2\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' develop --no-deps\n",
      "         cwd: C:\\Users\\gabriele.ferrario\\OneDrive - Accenture\\Desktop\\tesi\\datasets\\flickr30k_images\\detectron2\\\n",
      "    Complete output (20 lines):\n",
      "    No CUDA runtime is found, using CUDA_HOME='C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA\\v11.4'\n",
      "    running develop\n",
      "    running egg_info\n",
      "    writing detectron2.egg-info\\PKG-INFO\n",
      "    writing dependency_links to detectron2.egg-info\\dependency_links.txt\n",
      "    writing requirements to detectron2.egg-info\\requires.txt\n",
      "    writing top-level names to detectron2.egg-info\\top_level.txt\n",
      "    C:\\Users\\gabriele.ferrario\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\cpp_extension.py:381: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
      "      warnings.warn(msg.format('we could not find ninja.'))\n",
      "    writing manifest file 'detectron2.egg-info\\SOURCES.txt'\n",
      "    running build_ext\n",
      "    C:\\Users\\gabriele.ferrario\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\cpp_extension.py:316: UserWarning: Error checking compiler version for cl: [WinError 2] The system cannot find the file specified\n",
      "      warnings.warn(f'Error checking compiler version for {compiler}: {error}')\n",
      "    building 'detectron2._C' extension\n",
      "    error: Microsoft Visual C++ 14.0 is required. Get it with \"Build Tools for Visual Studio\": https://visualstudio.microsoft.com/downloads/\n",
      "    Error in atexit._run_exitfuncs:\n",
      "    Traceback (most recent call last):\n",
      "      File \"C:\\Users\\gabriele.ferrario\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\colorama\\ansitowin32.py\", line 59, in closed\n",
      "        return stream.closed\n",
      "    ValueError: underlying buffer has been detached\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'C:\\Users\\gabriele.ferrario\\AppData\\Local\\Programs\\Python\\Python39\\python.exe' -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\gabriele.ferrario\\\\OneDrive - Accenture\\\\Desktop\\\\tesi\\\\datasets\\\\flickr30k_images\\\\detectron2\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\gabriele.ferrario\\\\OneDrive - Accenture\\\\Desktop\\\\tesi\\\\datasets\\\\flickr30k_images\\\\detectron2\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' develop --no-deps Check the logs for full command output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard->detectron2==0.6) (2.3.3)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard->detectron2==0.6) (1.43.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard->detectron2==0.6) (0.6.1)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard->detectron2==0.6) (0.37.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard->detectron2==0.6) (1.0.0)\n",
      "Requirement already satisfied: six in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from absl-py>=0.4->tensorboard->detectron2==0.6) (1.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.6) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from markdown>=2.6.8->tensorboard->detectron2==0.6) (4.10.1)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2021.5.30)\n",
      "Requirement already satisfied: tomli>=1.0.0 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from setuptools-scm>=4->matplotlib->detectron2==0.6) (1.2.2)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from portalocker->iopath<0.1.10,>=0.1.7->detectron2==0.6) (301)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->detectron2==0.6) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.6) (3.1.1)\n",
      "Installing collected packages: detectron2\n",
      "  Running setup.py develop for detectron2\n"
     ]
    }
   ],
   "source": [
    "#! pip3 install torch torchvision torchaudio --upgrade\n",
    "\n",
    "! python -m pip install -e detectron2 --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50607178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imantics in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.1.12)\n",
      "Requirement already satisfied: numpy in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from imantics) (1.21.2)\n",
      "Requirement already satisfied: opencv-python>=3 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from imantics) (4.5.4.58)\n",
      "Requirement already satisfied: lxml in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from imantics) (4.6.4)\n",
      "Requirement already satisfied: xmljson in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from imantics) (0.2.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.15.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (2021.11.10)\n",
      "Requirement already satisfied: filelock in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (3.4.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (5.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (0.0.47)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (1.21.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: requests in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from packaging>=20.0->transformers) (2.4.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:1123)'))': /simple/transformers/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: colorama in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (1.26.5)\n",
      "Requirement already satisfied: six in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: click in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sacremoses->transformers) (8.0.1)\n",
      "Requirement already satisfied: timm in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.5.4)\n",
      "Requirement already satisfied: torch>=1.4 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from timm) (1.10.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from timm) (0.11.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.4->timm) (3.10.0.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchvision->timm) (1.21.2)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchvision->timm) (8.4.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\gabriele.ferrario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (5.1)\n",
      "Collecting pyyaml\n",
      "  Using cached PyYAML-6.0-cp39-cp39-win_amd64.whl (151 kB)\n",
      "Installing collected packages: pyyaml\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 5.1\n",
      "    Uninstalling PyYAML-5.1:\n",
      "      Successfully uninstalled PyYAML-5.1\n",
      "Successfully installed pyyaml-6.0\n"
     ]
    }
   ],
   "source": [
    "! pip install imantics --upgrade\n",
    "\n",
    "! pip install transformers --upgrade\n",
    "\n",
    "! pip install timm --upgrade\n",
    "\n",
    "#!git clone https://github.com/facebookresearch/detectron2.git\n",
    "#!pip install ./detectron2 --upgrade\n",
    "!pip install --upgrade pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69ba3483",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'detectron2.utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\GABRIE~1.FER\\AppData\\Local\\Temp/ipykernel_11840/2061265666.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mimantics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msetup_logger\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0msetup_logger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodel_zoo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'detectron2.utils'"
     ]
    }
   ],
   "source": [
    "#from pandarallel import pandarallel\n",
    "#pandarallel.initialize()\n",
    "\n",
    "import os, json, cv2, random, sys, math, io, base64\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from imantics import Mask\n",
    "\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import DetrFeatureExtractor, DetrForSegmentation, DetrModel\n",
    "\n",
    "feature_extractor = DetrFeatureExtractor.from_pretrained(\"facebook/detr-resnet-101-panoptic\")\n",
    "model_detr = DetrForSegmentation.from_pretrained(\"facebook/detr-resnet-101-panoptic\")\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.MODEL.DEVICE='cpu'\n",
    "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"LVISv0.5-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_1x.yaml\"))\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
    "\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"LVISv0.5-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_1x.yaml\")\n",
    "\n",
    "model_maskrcnn = DefaultPredictor(cfg)\n",
    "\n",
    "from tensorflow.keras.applications.resnet import preprocess_input\n",
    "from tensorflow.keras.applications.resnet import ResNet101\n",
    "\n",
    "resnet = ResNet101(weights='imagenet', include_top=False, pooling='max')\n",
    "\n",
    "import pandas as pd\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb8229d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size(image_size):\n",
    "    min_size = 600\n",
    "    max_size = 1000\n",
    "    if not isinstance(min_size, (list, tuple)):\n",
    "        min_size = (min_size,)\n",
    "    w, h = image_size\n",
    "    size = random.choice(min_size)\n",
    "    if max_size is not None:\n",
    "        min_original_size = float(min((w, h)))\n",
    "        max_original_size = float(max((w, h)))\n",
    "        if max_original_size / min_original_size * size > max_size:\n",
    "            size = int(round(max_size * min_original_size / max_original_size))\n",
    "\n",
    "    if (w <= h and w == size) or (h <= w and h == size):\n",
    "        return (h, w)\n",
    "\n",
    "    if w < h:\n",
    "        ow = size\n",
    "        oh = int(size * h / w)\n",
    "    else:\n",
    "        oh = size\n",
    "        ow = int(size * w / h)\n",
    "\n",
    "    return (oh, ow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40897c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_additional_features(rect,h,w):\n",
    "    mask = np.array([w,h,w,h],dtype=np.float32)\n",
    "    rect = np.clip(rect/mask,0,1)\n",
    "    res = np.hstack((rect,[rect[3]-rect[1], rect[2]-rect[0]]))\n",
    "    return res.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9db999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features(ROI, features_extractor):\n",
    "    ROI = cv2.resize(np.float32(ROI), (224, 224), interpolation = cv2.INTER_LINEAR)\n",
    "    img_data = image.img_to_array(ROI)\n",
    "    img_data = np.expand_dims(img_data, axis=0)\n",
    "    img_data = preprocess_input(img_data)\n",
    "    feature = features_extractor.predict(img_data)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80beff99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_results(seg_outputs, model_name, classes, im, features_extractor, height, width, classes_lvis = [], bbox_id = 0, clean_image = []):\n",
    "    result = []\n",
    "    if model_name == \"LVIS\":\n",
    "    lvis_im = im\n",
    "    for class_name, bbox, mask, score in zip(seg_outputs[\"instances\"].pred_classes.cpu().numpy(), seg_outputs[\"instances\"].pred_boxes.tensor.cpu().numpy(), seg_outputs[\"instances\"].pred_masks.cpu().numpy(), seg_outputs[\"instances\"].scores.cpu().numpy()):\n",
    "        class_name = classes[str(class_name)].capitalize()\n",
    "        x,y,w,h = tuple(bbox)\n",
    "        mask = cv2.resize(np.float32(mask), (np.array(im).shape[1], np.array(im).shape[0]), interpolation = cv2.INTER_AREA)\n",
    "        ROI = np.where(mask[...,None]!=0, im, [255,255,255])[int(y):int(h), int(x):int(w)]\n",
    "        feature = compute_features(ROI, features_extractor)\n",
    "        feature = np.array(feature)\n",
    "        pos_feat = generate_additional_features(bbox, height, width)\n",
    "        feature_seg = feature.flatten() # le uso per filtrare gli oggetti\n",
    "        feature = np.hstack((feature_seg, pos_feat)).astype(np.float32)\n",
    "        ROI_region = im[int(y):int(h), int(x):int(w)] # usato per filtrare gli oggetti\n",
    "        result.append({\"rect\": bbox.tolist(), \"bbox_id\": bbox_id, \"class\": class_name, \"conf\": score,  \"feature_seg\": feature_seg, \"feature\": feature, \"feature_base64\": base64.b64encode(feature).decode(\"utf-8\"), \"features_bbox\": np.array(compute_features(ROI_region, features_extractor)).flatten()})\n",
    "        bbox_id += 1\n",
    "        classes_lvis.append(class_name)\n",
    "        lvis_im = np.where(mask[...,None]==0, lvis_im,[255,255,255])\n",
    "    return result, classes_lvis, lvis_im, bbox_id\n",
    "  \n",
    "    elif model_name == \"COCO\":\n",
    "        for i in range(len(seg_outputs[\"labels\"])):\n",
    "            coco_class = classes[str(seg_outputs[\"labels\"][i].numpy())].capitalize()\n",
    "            mask = seg_outputs[\"masks\"][i]\n",
    "            mask = cv2.resize(np.float32(mask), (np.array(im).shape[1], np.array(im).shape[0]), interpolation = cv2.INTER_AREA)\n",
    "            bbox = Mask(mask).bbox()\n",
    "            x,y,w,h = tuple(bbox)\n",
    "            area = w*h\n",
    "            if area >0:\n",
    "                ROI_region = im[int(y):int(h), int(x):int(w)]\n",
    "                if coco_class not in classes_lvis:\n",
    "                    ROI_clean = np.where(mask[...,None]!=0, clean_image, [255,255,255])[int(y):int(h), int(x):int(w)]\n",
    "                    number_of_white_pix_clean = np.sum(ROI_clean == 255)\n",
    "                    number_of_not_white_pix_clean = np.sum(ROI_clean != 255)\n",
    "                    if number_of_white_pix_clean  > number_of_not_white_pix_clean: # se l'immagine è troppo bianca (troppo segmentata) la nuova segmentazione è fatta su quella di partenza\n",
    "                        ROI = np.where(mask[...,None]!=0, im, [255,255,255])[int(y):int(h), int(x):int(w)]\n",
    "                        feature = compute_features(ROI, features_extractor)\n",
    "                    else:\n",
    "                        ROI = ROI_clean\n",
    "                        feature = compute_features(ROI, features_extractor)\n",
    "                elif coco_class in classes_lvis:\n",
    "                    ROI = np.where(mask[...,None]!=0, im, [255,255,255])[int(y):int(h), int(x):int(w)]\n",
    "                    feature = compute_features(ROI, features_extractor)\n",
    "\n",
    "                feature = np.array(feature)\n",
    "                clean_image = np.where(mask[...,None]==0, clean_image, [255,255,255]) # contiene la parte non segmentata da aggiungere eventualmente con classe vuota \"\"\n",
    "                bbox = list(bbox)\n",
    "                feature_seg = feature.flatten() # usato per filtrare gli oggetti\n",
    "                pos_feat = generate_additional_features(bbox, height, width)\n",
    "                feature = np.hstack((feature_seg, pos_feat)).astype(np.float32)\n",
    "                ROI_region = im[int(y):int(h), int(x):int(w)] # usato per filtrare gli oggetti\n",
    "                result.append({\"rect\": bbox, \"bbox_id\": bbox_id, \"class\": coco_class, \"conf\": seg_outputs[\"scores\"][i].item(), \"feature_seg\": feature_seg, \"feature\": feature, \"feature_base64\": base64.b64encode(feature).decode(\"utf-8\"), \"features_bbox\": np.array(compute_features(ROI_region, features_extractor)).flatten()})\n",
    "                bbox_id += 1\n",
    "        return result, clean_image, bbox_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcc323b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e46a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_segmentation_results(df): # elimina oggetti estratti simili\n",
    "    eliminated_index = [] # lista di appoggio per non eliminare elementi non più presenti\n",
    "    for index1, row1 in df.iterrows():\n",
    "        for index2, row2 in df.loc[(index1+1):].iterrows(): # salto i primi index1 elementi per ridurre il numero di iterazioni\n",
    "            featurs_similarity_bbox = 1 - spatial.distance.cosine(row1[\"features_bbox\"], row2[\"features_bbox\"])\n",
    "            featurs_similarity = 1 - spatial.distance.cosine(row1[\"feature_seg\"], row2[\"feature_seg\"])\n",
    "            bbox_similarity = 1 - spatial.distance.cosine(row1[\"rect\"], row2[\"rect\"])\n",
    "            if featurs_similarity > 0.7 and featurs_similarity_bbox > 0.7 and bbox_similarity > 0.98: # soglie di similarità\n",
    "                if row1[\"conf\"] > row2[\"conf\"] and index2 not in eliminated_index:\n",
    "                    df = df.drop(index2)\n",
    "                    eliminated_index.append(index2)\n",
    "                elif index1 not in eliminated_index:\n",
    "                df = df.drop(index1)\n",
    "                eliminated_index.append(index1)\n",
    "    return df\n",
    "\n",
    "def compute_extraction(im_cv2, maskrcnn, feature_extractor, detr, resnet, height, width):\n",
    "  \n",
    "    outputs = maskrcnn(im_cv2)\n",
    "    result, classes_lvis, lvis_im, bbox_id = compute_results(outputs, \"LVIS\", lvis, im_cv2, resnet, height, width)\n",
    "\n",
    "    im_pil =  Image.fromarray(im_cv2[:, :, ::-1]) # convert image in PIL format\n",
    "    encoding = feature_extractor(im_pil, return_tensors=\"pt\")\n",
    "    outputs = detr(**encoding)\n",
    "    processed_sizes = torch.as_tensor(encoding['pixel_values'].shape[-2:]).unsqueeze(0)\n",
    "    result_seg = feature_extractor.post_process_segmentation(outputs, processed_sizes, threshold = 0.6)[0]\n",
    "    result_lvis, clean_image, bbox_id = compute_results(result_seg, \"COCO\", coco, im_cv2, resnet, height, width, classes_lvis, bbox_id, lvis_im)\n",
    "    result = result + result_lvis\n",
    "    if np.sum(clean_image != 255) > np.sum(clean_image == 255)* 90/100: # aggiungo la parte non segmentata solo se più del 60% circa dei pixels non sono bianchi\n",
    "        feature_seg = np.array(compute_features(clean_image, resnet)).flatten()\n",
    "        bbox = [0, 0, clean_image.shape[1], clean_image.shape[0]]\n",
    "        pos_feat = generate_additional_features(bbox, height, width)\n",
    "        feature = np.hstack((feature_seg, pos_feat)).astype(np.float32)\n",
    "        bbox_id += 1\n",
    "        result.append({\"rect\": bbox, \"bbox_id\": bbox_id, \"class\": \"\", \"conf\": 0, \"feature_seg\": feature_seg, \"feature\": feature, \"feature_base64\": base64.b64encode(feature).decode(\"utf-8\"), \"features_bbox\": feature_seg})\n",
    "    df = pd.DataFrame(result)\n",
    "    return filter_segmentation_results(df)\n",
    "  \n",
    "def compute_row(img):\n",
    "    img_path = \"./flickr30k/train/\"+img\n",
    "    print(img_path)\n",
    "    im_cv2 = cv2.imread(img_path)\n",
    "    new_size = get_size((im_cv2.shape[1],im_cv2.shape[0]))\n",
    "    im_cv2 = cv2.resize(im_cv2, (new_size[1], new_size[0]), interpolation = cv2.INTER_AREA)\n",
    "    height = im_cv2.shape[0]\n",
    "    width = im_cv2.shape[1]\n",
    "    global model_maskrcnn\n",
    "    global feature_extractor\n",
    "    global model_detr\n",
    "    global resnet\n",
    "    df_extraction = compute_extraction(im_cv2, model_maskrcnn, feature_extractor, model_detr, resnet, height, width)\n",
    "    features_arr = df_extraction[\"feature\"].values \n",
    "    del df_extraction[\"feature\"]\n",
    "    df_extraction = df_extraction.rename(columns={\"feature_base64\": \"feature\"})\n",
    "    features = np.vstack(tuple(features_arr))\n",
    "    features = base64.b64encode(features).decode(\"utf-8\")\n",
    "    #predictions_column.append(json.dumps({\"objects\": df_extraction.to_dict(\"records\")})) # full predictions\n",
    "    series = pd.Series([json.dumps({\"features\":features, \"num_boxes\":len(features_arr)}), json.dumps(df_extraction[[\"class\", \"conf\", \"rect\"]].to_dict(\"records\"))])\n",
    "\n",
    "    series.to_csv('./features_test2/{}.csv'.format(img.replace(\".jpg\",\"\")))\n",
    "\n",
    "    return series \n",
    "\n",
    "from maskrcnn_benchmark.structures.tsv_file_ops import tsv_reader, tsv_writer\n",
    "import yaml\n",
    "import os.path as op\n",
    "from shutil import copyfile\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    f = open('./coco_categories_detr.json')\n",
    "    coco = json.load(f)\n",
    "\n",
    "    f = open('./lvis_categories_maskrcnn.json')\n",
    "    lvis = json.load(f)\n",
    "\n",
    "    sg_tsv = './data/train.hw.tsv'\n",
    "    df_train_hw = pd.read_csv(sg_tsv,sep='\\t',header = None,converters={1:json.loads})#converters={1:ast.literal_eval})\n",
    "    print(\"Numero di immagini: {}\".format(len(df_train_hw)))\n",
    "\n",
    "    df_predictions = pd.DataFrame({\"image_id\": df_train_hw[0]})\n",
    "    df_predictions[\"img\"] = df_predictions[\"image_id\"].apply(lambda x: str(x)+\".jpg\") #.zfill(12)\n",
    "    df_predictions = df_predictions.iloc[1121:]\n",
    "    df_predictions = df_predictions[~df_predictions[\"img\"].isin([sub.replace(\".csv\", \".jpg\") for sub in os.listdir(\"./features_test2/\")])]\n",
    "\n",
    "    #df_predictions[[\"features\", \"label\"]] = df_predictions['img'].parallel_apply(compute_row)\n",
    "    df_predictions[[\"features\", \"label\"]] = df_predictions['img'].progress_apply(compute_row)\n",
    "    print(\"Features estratte\")\n",
    "\n",
    "    OUTPUT_DIR = 'Oscar/inference_test_segmentation/'\n",
    "    LABEL_FILE = os.path.join(OUTPUT_DIR,'label.tsv')\n",
    "    FEATURE_FILE = os.path.join(OUTPUT_DIR,'features.tsv')\n",
    "    if not os.path.exists(OUTPUT_DIR):\n",
    "        os.makedirs(OUTPUT_DIR)\n",
    "        print(f\"path to {OUTPUT_DIR} created\")\n",
    "  \n",
    "    tsv_writer(df_predictions[['image_id','label']].values.tolist(),LABEL_FILE)\n",
    "    tsv_writer(df_predictions[['image_id','features']].values.tolist(),FEATURE_FILE)\n",
    "\n",
    "    yaml_dict = {\"label\": \"label.tsv\",\n",
    "               \"feature\": \"features.tsv\",\n",
    "               \"img\": \"train.tsv\",\n",
    "               \"hw\": \"train.hw.tsv\"}\n",
    "\n",
    "    with open(op.join(OUTPUT_DIR, 'test.yaml'), 'w') as file:\n",
    "          yaml.dump(yaml_dict, file)\n",
    "\n",
    "    copyfile(\"./data/train.hw.tsv\", os.path.join(OUTPUT_DIR,'train.hw.tsv'))\n",
    "    #copyfile(\"./data/train.tsv\", os.path.join(OUTPUT_DIR,'train.tsv'))\n",
    "    print(\"File .tsv creati\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
